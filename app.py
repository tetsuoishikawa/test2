import streamlit as st
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import re
import gc

MODEL_REPO = "Tetsuo3003/ner-medical-japanese"

@st.cache_resource
def load_pipeline():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_REPO, use_fast=False)
    model = AutoModelForTokenClassification.from_pretrained(MODEL_REPO, low_cpu_mem_usage=False)
    return pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

ner_pipeline = load_pipeline()

LABEL_COLORS = {
    "PER": "#FF6666", "ORG": "#66B2FF", "LOC": "#66FF66", "INS": "#FFCC66",
    "PRD": "#CC99FF", "EVT": "#FF99CC", "ORG-P": "#FFB266", "ORG-O": "#FFB266"
}

def mask_entities(text, entities):
    masked_text = text
    for entity in sorted(entities, key=lambda x: -len(x['word'])):
        label = entity['entity_group']
        color = LABEL_COLORS.get(label, "#CCCCCC")
        replacement = f"<span style='color: {color}; font-weight: bold;'>[{label}]</span>"
        masked_text = re.sub(re.escape(entity['word']), replacement, masked_text)
    return masked_text

st.title("ğŸ©º æ—¥æœ¬èª åŒ»ç™‚ä¼šè©± NER ã‚¢ãƒ—ãƒª")

text = st.text_area("è§£æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ500æ–‡å­—ã¾ã§ï¼‰:",
                    "é‡‘ä¸¸å…ˆç”ŸãŒæ¾æœ¬å¸‚ã«ã‚ã‚‹çŸ³å·ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã«é€šé™¢ã—ã¾ã—ãŸã€‚", max_chars=500)

if st.button("è§£æé–‹å§‹"):
    with st.spinner("è§£æä¸­..."):
        results = ner_pipeline(text)
        masked_text = mask_entities(text, results)

        st.subheader("ğŸ“ ä»®ååŠ å·¥ï¼ˆãƒã‚¹ã‚­ãƒ³ã‚°ï¼‰å¾Œã®æ–‡ç« ")
        st.markdown(masked_text, unsafe_allow_html=True)

        st.subheader("ğŸ” æŠ½å‡ºã—ãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¸€è¦§")
        if results:
            for entity in results:
                st.write(f"- **{entity['word']}** â†’ {entity['entity_group']} (ä¿¡é ¼åº¦: {entity['score']:.2f})")
        else:
            st.info("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

        del results
        gc.collect()
